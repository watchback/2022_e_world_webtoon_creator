{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a9bb5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "import csv\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "688deb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selenium 웹 드라이버를 시작합니다. \n",
    "driver = webdriver.Chrome(service= Service(ChromeDriverManager().install()))  # 크롬 드라이버 경로를 설정하세요.\n",
    "\n",
    "# Pubmed 검색 URL을 생성합니다.\n",
    "base_url = \"https://pubmed.ncbi.nlm.nih.gov/?term=\"\n",
    "search_query = \"Lung toxic chemical\"  # 검색어를 원하는 키워드로 변경하세요.\n",
    "search_url = base_url + search_query\n",
    "\n",
    "# 1페이지부터 10페이지까지 반복합니다.\n",
    "for page in range(1, 284):\n",
    "    # 페이지 번호를 포함한 완전한 URL을 생성합니다.\n",
    "    page_url = search_url + \"&filter=years.2000-2023\" + f\"&page={page}\"\n",
    "\n",
    "    # 생성된 URL로 이동합니다.\n",
    "    driver.get(page_url)\n",
    "\n",
    "    # 페이지가 로드될 때까지 기다립니다. (필요에 따라 적절한 대기 시간을 설정해야 합니다)\n",
    "    time.sleep(3)  # 2초 대기 (필요에 따라 조정)\n",
    "    results = driver.find_elements(By.CSS_SELECTOR, \".docsum-title\")\n",
    "\n",
    "    with open(\"lung toxic chemical.csv\", mode=\"a\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "\n",
    "        # 논문 제목을 CSV 파일에 작성\n",
    "        for result in results:\n",
    "            writer.writerow([result.text])\n",
    "\n",
    "# 작업이 끝나면 웹 드라이버를 종료합니다.\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8e2385",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/csb/CSB_hanjin/ai/life chemical lung toxicity.csv\",encoding='unicode_escape')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42584c2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 불용어 목록을 가져옵니다.\n",
    "stop_words = set(stopwords.words('english'))  # 영어 불용어 목록을 사용하겠습니다.\n",
    "\n",
    "# 데이터프레임의 각 셀에서 불용어를 제거합니다.\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "def remove_dot(text):\n",
    "    return text.replace(',', '')\n",
    "\n",
    "def remove_dot2(text):\n",
    "    return text.replace('.', '')\n",
    "\n",
    "def remove_dot3(text):\n",
    "    return text.replace(':', '')\n",
    "\n",
    "def remove_dot4(text):\n",
    "    return text.replace('-', ' ')\n",
    "\n",
    "def remove_dot5(text):\n",
    "    return text.replace('\"', '')\n",
    "\n",
    "def remove_dot6(text):\n",
    "    return text.replace('(', '')\n",
    "\n",
    "def remove_dot7(text):\n",
    "    return text.replace(')', '')\n",
    "\n",
    "def remove_dot8(text):\n",
    "    return text.replace('[', '')\n",
    "\n",
    "def remove_dot9(text):\n",
    "    return text.replace(']', '')\n",
    "\n",
    "def remove_numbers(text):\n",
    "    return ''.join([char for char in text if not char.isdigit()])\n",
    "\n",
    "# 'text_column' 열의 각 셀에서 '.' 문자를 제거합니다.\n",
    "data['Paper'] = data['Paper'].apply(remove_dot)\n",
    "data['Paper'] = data['Paper'].apply(remove_dot2)\n",
    "data['Paper'] = data['Paper'].apply(remove_dot3)\n",
    "data['Paper'] = data['Paper'].apply(remove_dot4)\n",
    "data['Paper'] = data['Paper'].apply(remove_dot5)\n",
    "data['Paper'] = data['Paper'].apply(remove_dot6)\n",
    "data['Paper'] = data['Paper'].apply(remove_dot7)\n",
    "data['Paper'] = data['Paper'].apply(remove_dot8)\n",
    "data['Paper'] = data['Paper'].apply(remove_dot9)\n",
    "data['Paper'] = data['Paper'].apply(remove_numbers)\n",
    "\n",
    "# 'text_column' 열의 각 셀에서 불용어를 제거합니다.\n",
    "data['Paper'] = data['Paper'].apply(remove_stopwords)\n",
    "\n",
    "\n",
    "\n",
    "# 결과 출력\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac45788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 데이터프레임에서 모든 단어를 하나의 문자열로 합칩니다.\n",
    "text = \" \".join(data['Paper'])\n",
    "\n",
    "# 워드 클라우드 생성\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
    "\n",
    "# 워드 클라우드를 플롯합니다.\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a58cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = \" \".join(data['Paper']).split()\n",
    "\n",
    "word_counts = Counter(words)\n",
    "\n",
    "# 결과를 데이터프레임으로 변환합니다.\n",
    "word_counts_df = pd.DataFrame.from_dict(word_counts, orient='index', columns=['count'])\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "word_counts_df.to_csv('word_counts.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f16d83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
